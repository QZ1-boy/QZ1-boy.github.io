<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="files/jemdoc.css" type="text/css" />
<link rel="icon" href="./img/xy-favicon.ico">
<title>QiangZhu</title>
</head>
<body>

<div class="menu"> <a href="#home">Home</a>
<a href="#education">Experience</a>
<a href="#publications">Publications</a>
<a href="#services">Services</a>
<a href="#awards">Awards</a>
</div>

<a id="home" class="anchor"></a>
<div id="container">
<div class="container">
<div id="toptitle">
<h1>Qiang Zhu&nbsp;&nbsp;</h1>
</div>

<table class="imgtable"><tr><td>
<a href="./"><img src="./img/QZ.jpg" alt="" height="230px" width="300px"/></a>&nbsp;</td>
<td align="left"><p><a href="./"><font size="4">Qiang Zhu</font></a><br />
<i> Ph.D., Post-doctor Researcher </i>
<br /><br />
<!-- <td align="left"><p><font color="#424949" size="4.8"><b>Post-doctor Researcher </b></font><br> -->
<a href="https://www.pcl.ac.cn/">Peng Cheng Laboratory (PCL)</a><br />
Media and Interaction Department, Shenzhen, China<br />

</i></font>&nbsp;<br />
<a href="https://scholar.google.co.uk/citations?user=scgM6GgAAAAJ&hl=en&oi=ao"><img src="./img/google_scholar.png" height="20px" style="margin-bottom:-3px"/>&nbsp;Google Scholar</a>&nbsp;&nbsp;
<a href="https://dblp.org/pid/34/6522.html"><img src="./img/DBLP_logo.png" height="20px" style="margin-bottom:-3px"/>&nbsp;DBLP</a>&nbsp;&nbsp;
<a href="https://orcid.org/0000-0003-2959-0641"><img src="./img/ORCID.png" height="20px" style="margin-bottom:-3px"/>&nbsp;ORCID</a>&nbsp;&nbsp; 
<a href="https://github.com/QZ1-boy"><img src="./img/github.png" height="20px" style="margin-bottom:-3px"/>&nbsp;GitHub</a>&nbsp;&nbsp;
<br />  

<br>üì© Email: zhuqiang@std.uestc.edu.cn, zhuqiang@pcl.ac.cn <br />
<br>üìå <b>Research Topic: Low-level Vision, 3D Scene Reconstruction, Compression.</b><br />
</p>
</td></tr></table>

<h2>Biography</h2>
<p>I am a Post-doctor Researcher in <a href="hhttps://www.pcl.ac.cn/" target="_blank">Peng Cheng Laboratory (PCL)</a>, supervised by Prof. <a href="https://www.ece.pku.edu.cn/info/1046/2147.htm" target="_blank"><font color="#1772d0">Ronggang Wang</font></a>. 
    In 2025, I obtained the Ph.D. degree in <a href="https://www.uestc.edu.cn/" target="_blank">University of Electronic Science and Technology of China (UESTC)</a>, supervised by Prof. <a href="https://faculty.uestc.edu.cn/shuyuanzhu/zh_CN/index.htm" target="_blank"><font color="#1772d0"> Shuyuan Zhu (IEEE Senior Member) </font></a> and Prof.<a href="https://faculty.uestc.edu.cn/zengbing/zh_CN/index.htm" target="_blank"><font color="#1772d0"> Bing Zeng (IEEE Fellow)</font></a>. 
    In 2023, I interned at <a href="https://www.kuaishou.com/en" target="_blank"><font color="#1772d0"> Kuaishou Technology</font></a>, 
    under the supervision of <a href="https://scholar.google.co.uk/citations?user=1b1jbCQAAAAJ&hl=en&oi=ao" target="_blank"><font color="#1772d0"> Ming Sun</font></a>. 
    In 2024-2025, I served as a Ph.D visiting student at <a href="https://www.bristol.ac.uk/" target="_blank"><font color="#1772d0"> University of Bristol</font></a>, United Kingdom,
    under the supervision of Dr. <a href="https://scholar.google.co.uk/citations?user=BBujJNcAAAAJ&hl=en&oi=ao" target="_blank"><font color="#1772d0"> Aaron Zhang (IEEE Senior Member) </font></a> and Prof.<a href="https://www.bristol.ac.uk/people/person/David-Bull-f53987d8-4d62-431b-8228-2d39f944fbfe/" target="_blank"><font color="#1772d0"> David Bull (IEEE Life Fellow)</font></a> in <a href="https://vilab.blogs.bristol.ac.uk/" target="_blank"><font color="#1772d0">VILab</font></a>.
    My research interests include low-level vision, video compression and 3D scene reconstruction.
</p>

<h2>News</h2>
<!-- <div style="height: 240px; overflow-y: auto; overflow-x: hidden;">  ‰ΩøÁî®Á™óÂè£ÊªëÂä®ÊòæÁ§∫ÔºåÊµèËßàÂô®ÂÆπÊòì‰∏çÂÖºÂÆπ  -->
<ul>
<li><font color="black">(02/2026)</font> One paper <a href="https://ieeexplore.ieee.org/Xplore/home.jsp"> VRPC</a> was accepted by <b>IEEE TBC</b>. </li>
<li><font color="black">(01/2026)</font> One paper <a href="https://arxiv.org/abs/2508.10453"> TS-Mamba</a> was accepted by <b>ICLR 2026</b>. </li>
<li><font color="black">(10/2025)</font> One paper <a href="https://arxiv.org/abs/2502.06431"> FCVSR</a> was accepted by <b>IEEE TMM</b>. </li>
<li><font color="black">(06/2025)</font> One paper <a href="https://ieeexplore.ieee.org/Xplore/home.jsp" target="_blank"> BVSR-IK</a> was accepted by <b>ICCV 2025</b>. </li>
<li><font color="black">(05/2025)</font> We won the <b><font color="#DA1212">First Prize</font></b> in <a href="https://iscasnnvcgc.github.io/"> Neural Network Video Coding Grand Challenge (Hybrid Track) in IEEE ISCAS 2025</a>. </li>    
<li><font color="black">(03/2025)</font> One paper <a href="https://ieeexplore.ieee.org/Xplore/home.jsp" target="_blank"> PGQE</a> was accepted by <b>IEEE TMM</b>. </li>
<li><font color="black">(10/2024)</font> One paper <a href="https://link.springer.com/chapter/10.1007/978-3-031-72670-5_3" target="_blank"> OAPT</a> was accepted by <b>ECCV 2024</b>. </li>
<li><font color="black">(06/2024)</font> One paper <a href="https://ieeexplore.ieee.org/document/10656889" target="_blank"> CPGA</a> was accepted by <b>CVPR 2024</b> and officially reported by <b>Kuaishou Technology</b> <a href="https://mp.weixin.qq.com/s/ixog0p_bYTv_daMjTAwEyA" target="_blank">[News Link]</a>. </li>
<li><font color="black">(05/2024)</font> One paper <a href="https://ieeexplore.ieee.org/document/10536024" target="_blank">CDFO</a> was accepted by <b>IEEE TBC</b>.</li>
<li><font color="black">(04/2024)</font> One paper <a href= "https://ieeexplore.ieee.org/document/10555432" target="_blank">TGAF</a> was accepted by <b>IEEE SPL</b>.</li>
<li><font color="black">(01/2024)</font> One paper <a href= "https://ieeexplore.ieee.org/document/10555432" target="_blank">DVSRNet</a> was accepted by <b>IEEE TNNLS</b> and officially reported by <b>UESTC</b> and <b>SICE</b> <a href="https://news.uestc.edu.cn/?n=UestcNews.Front.DocumentV2.ArticlePage&Id=92741" target="_blank">[News Link]</a><a href="https://www.sice.uestc.edu.cn/info/1136/14233.htm" target="_blank">[News Link]</a>.</li>
<li><font color="black">(06/2023)</font> We won the <b><font color="#DA1212">Third Prize</font></b> in <a href="https://ieeexplore.ieee.org/document/10208836/" target="_blank"> NTIRE 2023 Challenge  on Image Super-Resolution (x4)</a>. </li>    
</ul>
<!-- </div> -->

<a id="education" class="anchor"></a>
<h2>Experience</h2>
<!-- <p><b>Education:</b></p> -->
<ul>
<li> 2019.09~2025.06 &emsp;&emsp; <b>Ph.D.</b> in University of Electronic Science and Technology of China (Recommended) </li>
   
<li> 2015.09~2019.06 &emsp;&emsp; <b>B.S.</b> in University of Electronic Science and Technology of China </li>
</ul>

<!-- Impact Factor List -->
<script>
# var citation=1128;
ifif=14.7;
isprsif=10.6;
tipif=10.8;
tmmif=8.4;
tcsvtif=8.3;
tnnlsif=10.2;
tgrsif=7.5;
jagif=7.6;
stotenif=8.2;
gsisif=4.4;
jasif=15.3;
</script>
    
<!-- Publications -->
<a id="publications" class="anchor"></a>

<h2>Selected Publications 
<!-- [<a href="https://scholar.google.co.uk/citations?user=scgM6GgAAAAJ&hl=en&oi=ao">&nbsp;<img src="./img/gs.png" height="20px" style="margin-bottom:-3px"/></a>Citation<script>document.write(citation)</script>&nbsp;] -->
</h2>
<p><b>Conference:</b> ICLR(1), CVPR (1), ICCV (1), ECCV (1), CVPRW (1), ISCAS (1), MMSP (1)</p> 
<p><b>Journal:</b>    TNNLS (1), TMM (2), TCSVT (1), TBC (2), SPL (1), ISPRS (1), GRSL (1)</p> 
<br>
<table class="imgtable"> 

<tr>
<td><img class="proj_thumb" src="./papers/TSMamba.png" alt="" height="90px"/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://arxiv.org/abs/2508.10453" target="_blank">
<font color="black"><b>Trajectory-aware Shifted State Space Models for Online Video Super-Resolution
</b></font></a></p>
<p class="pub_author"><u><b>Q. Zhu</b></u>, X. Meng, Y. Jiang, F. Zhang, D. Bull, S. Zhu, B. Zeng, R. Wang<br>
International Conference on Learning Representations (<b>ICLR</b>), 2026<br>
[<a href= "https://arxiv.org/abs/2508.10453">PDF</a>]  
[<a href="https://github.com/QZ1-boy">Code</a>]
</p>  
<br>
</td>
</tr>

    
    
<tr>
<td><img class="proj_thumb" src="./papers/BVSR-IK.png" alt="" height="90px"/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://ieeexplore.ieee.org/document/10656889" target="_blank">
<font color="black"><b>Blind Video Super-Resolution based on Implicit Kernels
</b></font></a></p>
<p class="pub_author"><u><b>Q. Zhu</b></u>, Y. Jiang, S. Zhu, F. Zhang, D. Bull, B. Zeng<br>
IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), (CCF-A), 2025<br>
[<a href= "https://arxiv.org/abs/2503.07856">PDF</a>]  
[<a href="https://github.com/QZ1-boy/BVSR-IK">Code</a>]
</p>  
<br>
</td>
</tr>
   
    

<tr>
<td><img class="proj_thumb" src="./papers/CVPR.png" alt="" height="90px"/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://ieeexplore.ieee.org/document/10656889" target="_blank">
<font color="black"><b>CPGA: Coding Priors-Guided Aggregation Network for Compressed Video Quality Enhancement
</b></font></a></p>
<p class="pub_author"><u><b>Q. Zhu</b></u>, J. Hao, Y. Ding, Q. Mo, M. Sun, C. Zhou, S. Zhu<br>
IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), (CCF-A), 2024<br>
[<a href= "https://ieeexplore.ieee.org/document/10656889">PDF</a>]  
[<a href="https://github.com/QZ1-boy/CPGA">Code</a>]
</p>  
<br>
</td>
</tr>
    
<tr>
<td><img class="proj_thumb" src="./papers/FCVSR.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://arxiv.org/abs/2502.06431" target="_blank">
<!-- <span class="tag">INFFUS'23</span> &nbsp;  -->
<font color="black"><b> FCVSR: A Frequency-aware Method for Compressed Video Super-Resolution</b></font></a></p>
<p class="pub_author"><u><b>Q. Zhu</b></u>, F. Zhang, F. Chen, S. Zhu, D. Bull, B. Zeng<br>
IEEE Transactions on Multimedia (<b>IEEE TMM</b>), (SCI Q1 TOP), 2025<br> 
[<a href= "https://ieeexplore.ieee.org/document/10398274">PDF</a>]  
[<a href="https://github.com/QZ1-boy/FCVSR" target="_blank">Code</a>]
</p>
</p>
<br>
</td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/TNNLS.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://ieeexplore.ieee.org/document/10398274" target="_blank">
<!-- <span class="tag">INFFUS'23</span> &nbsp;  -->
<font color="black"><b> DVSRNet: Deep Video Super-Resolution Based on Progressive Deformable Alignment and Temporal-Sparse Enhancement</b></font></a></p>
<p class="pub_author"><u><b>Q. Zhu</b></u>, F. Chen, S. Zhu, X. Zhou, R. Xiong, Y. Liu, B. Zeng<br>
IEEE Transactions on Neural Networks and Learning Systems  (<b>IEEE TNNLS</b>), (SCI Q1 TOP), 2024<br> 
[<a href= "https://ieeexplore.ieee.org/document/10398274">PDF</a>]  
[<a href="https://github.com/QZ1-boy/DVSRNet">Code</a>]
</p>
</p>
<br>
</td>
</tr>



<tr>
<td><img class="proj_thumb" src="./papers/TBC.png" alt="" height="90px"/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://ieeexplore.ieee.org/document/10536024" target="_blank">
<font color="black"><b>Deep Compressed Video Super-Resolution With Guidance of Coding Priors
</b></font></a></p>
<p class="pub_author"><u><b>Q. Zhu</b></u>, F. Chen, Y. Liu, S. Zhu, B. Zeng<br>
IEEE Transactions on Broadcasting (<b>IEEE TBC</b>), (SCI Q1), 2024<br>
[<a href= "https://ieeexplore.ieee.org/document/10536024">PDF</a>] 
[<a href="https://github.com/QZ1-boy/CDFO">Code</a>]
</p>  
</td>
</tr>
    

<tr>
<td><img class="proj_thumb" src="./papers/SPL.png" alt="" height="90px"/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://ieeexplore.ieee.org/document/10555432" target="_blank">
<font color="black"><b>Compressed Video Quality Enhancement With Temporal Group Alignment and Fusion
</b></font></a></p>
<p class="pub_author"><u><b>Q. Zhu</b></u>, Y. Qiu, Y. Liu, S. Zhu, B. Zeng<br>
IEEE Signal Processing Letters (<b>IEEE SPL</b>), (SCI Q2 TOP), 2024<br>
[<a href= "https://ieeexplore.ieee.org/document/10555432" target="_blank">PDF</a>] 
[<a href="https://github.com/QZ1-boy/TGAF-pytorch" target="_blank">Code</a>] 
</p>
</td>
</tr>



<tr>
<td><img class="proj_thumb" src="./papers/CVPRW.png" alt="" height="90px"/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://ieeexplore.ieee.org/document/10208836" target="_blank">
<font color="black"><b>Attention Retractable Frequency Fusion Transformer for Image Super Resolution
</b></font></a></p>
<p class="pub_author"><u><b>Q. Zhu</b></u>, P. Li, Q. Li<br>
IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (<b>CVPRW</b>), 2023<br>
[<a href= "https://ieeexplore.ieee.org/document/10208836" target="_blank">PDF</a>] 
[<a href="https://github.com/UESTCIPLAB/ARFT_for_NTIRE2023_Image_Super_Resolution" target="_blank">Code</a>] 
‚≠ê <b><font color="#DA1212" size="2">Third Prize of NTIRE 2023 Challenge  on Image Super-Resolution (x4) </font></b><br><br>
</p>  
</td>
</tr>


    
<tr>
<td><img class="proj_thumb" src="./papers/MMSP.png" alt="" height="90px"/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://ieeexplore.ieee.org/document/9949300" target="_blank">
<font color="black"><b>Deep Video Super-Resolution with Flow-Guided Deformable Alignment and Sparsity-based Temporal-Spatial Enhancement
</b></font></a></p>
<p class="pub_author"><u><b>Q. Zhu</b></u>, H. Zhang, S. Zhu, G. Liu, X. Zhen, B. Zeng<br>
IEEE 24th International Workshop on Multimedia Signal Processing (<b>IEEE MMSP</b>), <font color="#DA1212" size="2"><b>Oral</b></font>, 2022<br>
[<a href= "https://ieeexplore.ieee.org/document/9949300" target="_blank">PDF</a>] 
‚≠ê <b><font color="#DA1212" size="2">IEEE MMSP Top10% Award</font></b><br><br>
</p>  
</td>
</tr>


<tr>
<td><img class="proj_thumb" src="./papers/TMM_PDQE.png" alt="" height="90px"/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://ieeexplore.ieee.org/document/11180113" target="_blank">
<font color="black"><b>Projection Difference-guided Geometry Quality Enhancement for Video-based Point Cloud Compression
</b></font></a></p>
<p class="pub_author">Y. Liu, J. Bao, Z. Li, <u><b>Q. Zhu</b></u>, S. Zhu, S. Au Yeung, B. Zeng<br>
IEEE Transactions on Multimedia (<b>IEEE TMM</b>), (SCI Q1 TOP), 2025<br>
[<a href= "https://ieeexplore.ieee.org/document/11180113" target="_blank">PDF</a>] 
</p>  
</td>
</tr>


<tr>
<td><img class="proj_thumb" src="./papers/TMM_PDQE.png" alt="" height="90px"/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://ieeexplore.ieee.org/document/11180113" target="_blank">
<font color="black"><b>Virtual Reference-based Predictive Coding for V-PCC Attribute Compression
</b></font></a></p>
<p class="pub_author">Y. Liu, S. Zhu, <u><b>Q. Zhu</b></u>, S. Au Yeung, B. Zeng<br>
IEEE Transactions on Broadcasting (<b>IEEE TBC</b>), (SCI Q2), 2026<br>
[<a href= "https://ieeexplore.ieee.org/document/11180113" target="_blank">PDF</a>] 
</p>  
</td>
</tr>


<tr>
<td><img class="proj_thumb" src="./papers/ISCAS.png" alt="" height="90px"/>&nbsp;</td> 
<td>
<p class="pub_title"><a href= "https://ieeexplore-dev.ieee.org/document/11043854" target="_blank">
<font color="black"><b>Cross-Space Alignment-based Attribute Artifact Removal for V-PCC
</b></font></a></p>
<p class="pub_author">Y. Liu, M. Hu, <u><b>Q. Zhu</b></u>, Z. Li, SKA. Yeung, S. Zhu, L. He, F. Zhang<br>
2025 IEEE International Symposium on Circuits and Systems (<b>IEEE ISCAS</b>), (CCF-C), 2025<br>
[<a href= "https://ieeexplore.ieee.org/document/11043854" target="_blank">PDF</a>] 
</p>  
</td>
</tr>




<tr>
<td><img class="proj_thumb" src="./papers/VSRHE.png" alt="" height="90px"/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://arxiv.org/abs/2506.14381" target="_blank">
<font color="black"><b>Compressed Video Super-Resolution based on Hierarchical Encoding
</b></font></a></p>
<p class="pub_author">Y. Jiang, S. Teng, <u><b>Q. Zhu</b></u>, C. Feng, C. Zeng, F. Zhang, S. Zhu, B. Zeng, D. Bull<br>
- (<b>Arxiv</b>), 2025<br>
[<a href= "https://ieeexplore.ieee.org/Xplore/home.jsp" target="_blank">PDF</a>] 
</p>  
</td>
</tr>




<tr>
<td><img class="proj_thumb" src="./papers/TCSVT.png" alt="" height="90px"/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://ieeexplore.ieee.org/document/10189806" target="_blank">
<font color="black"><b>Dual Circle Contrastive Learning-Based Blind Image Super-Resolution
</b></font></a></p>
<p class="pub_author">Y. Qiu, <u><b>Q. Zhu</b></u>, S. Zhu, B. Zeng<br>
IEEE Transactions on Circuits and Systems for Video Technology  (<b>IEEE TCSVT</b>), (SCI Q1 TOP), 2024<br>
[<a href= "https://ieeexplore.ieee.org/document/10189806" target="_blank">PDF</a>] 
</p>
</td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/ECCV.png" alt="" height="90px"/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://link.springer.com/chapter/10.1007/978-3-031-72670-5_3" target="_blank">
<font color="black"><b>OAPT: Offset-Aware Partition Transformer for Double JPEG Artifacts Removal
</b></font></a></p>
<p class="pub_author">Q. Mo, Y. Ding, J. Hao, <u><b>Q. Zhu</b></u>, M. Sun, C. Zhou, F. Chen, S. Zhu<br>
European Conference on Computer Vision (<b>ECCV</b>), 2024<br>
[<a href= "https://link.springer.com/chapter/10.1007/978-3-031-72670-5_3" target="_blank">PDF</a>] 
[<a href="https://github.com/QMoQ/OAPT" target="_blank">Code</a>] 
</p>  
</td>
</tr>




<tr>
<td><img class="proj_thumb" src="./papers/GRSL.png" alt="" height="90px"/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://ieeexplore.ieee.org/document/9730832" target="_blank">
<font color="black"><b>Infrared Small Target Detection Using Local Feature-Based Density Peaks Searching
</b></font></a></p>
<p class="pub_author"><u><b>Q. Zhu</b></u>, S. Zhu, G. Liu, and Z. Peng<br>
IEEE Geoscience and Remote Sensing Letters (<b>IEEE GRSL</b>), (SCI Q2), 2022<br>
[<a href= "https://ieeexplore.ieee.org/document/9730832" target="_blank">PDF</a>] 
</p>  
</td>
</tr>


<tr>
<td><img class="proj_thumb" src="./papers/ISPRS.png" alt="" height="90px"/>&nbsp;</td>
<td>
<p class="pub_title"><a href= "https://www.sciencedirect.com/science/article/pii/S0924271621002392" target="_blank">
<font color="black"><b>Infrared Dim Target Detection via Mode-k1k2 Extension Tensor Tubal Rank under Complex Ocean Environment
</b></font></a></p>
<p class="pub_author">Z. Cao, X. Kong, <u><b>Q. Zhu</b></u>, S. Cao, and Z. Peng<br>
ISPRS Journal of Photogrammetry and Remote Sensing (<b>ISPRS PRS</b>), (SCI Q1 TOP), 2021<br>
[<a href= "https://www.sciencedirect.com/science/article/pii/S0924271621002392" target="_blank">PDF</a>] 
</p>  
</td>
</tr>



</table>

<!-- Editor Services Here -->
<a id="services" class="anchor"></a>
<h2>Academic Services</h2>
<p><b>Peer Review: </b></p>
<!-- <font size="3"> -->
<ul>
<li><b>Conference Reviewer:</b> CVPR, ICCV, ICLR, ICML, NeurIPS, ACM MM, AAAI, WACV. 
<li><b>Journal Reviewer:</b> IEEE TPAMI, TIP, TNNLS, TCSVT, TBC, and Knowledge-Based Systems. 

</ul>

<!-- Editor Award Here -->
<a id="awards" class="anchor"></a>
<h2>Awards and Honors</h2>
<ul>
<li><font color="#DA1212">First Prize</font> of Neural Network Video Coding Grand Challenge in IEEE ISCAS, 2025.</li>
<li><font color="#DA1212">Third Prize</font> of NTIRE Challenge on Image Super-Resolution (x4), 2023.</li>
<li><font color="#DA1212">Top10% Award</font> of IEEE MMSP, 2022.</li>
<li><font color="#DA1212">Outstanding Graduates</font> of UESTC, 2025.</li>
<li><font color="#DA1212"></font> Academic Newcomer Award of UESTC, 2024.</li>
<li><font color="#DA1212">National Scholarship</font> of Chinese Ministry of Education, 2024.</li>
<li><font color="#DA1212"> National Jointly Ph.D Scholarship</font> of China Scholarship Council, 2024.</li>
<!-- <li><font color="#DA1212"></font> Excellent Graduate Student of UESTC, 2021,2022,2024.</li> -->
<!-- <li><font color="#DA1212"></font> First Prize of Graduate Academic of UESTC, 2020,2021,2022,2024.</li>  -->
<li><font color="#DA1212"></font>National Encouragement Scholarship  of Chinese Ministry of Education, 2017,2018.</li>


</ul>

<div id="footer">
<!-- <div id="footer-text"> -->
<p style="text-align:center;">Copyright @ 2024 Qiang Zhu. All rights reserved.</p>
<!-- </div> -->
</div>

</div>
</div>

</body>
</html>
